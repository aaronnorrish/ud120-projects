### Lesson 12.17 Lasso Code Quiz
The following line should be added:
```
regression.fit(features, labels)
```

### Lesson 12.18 Lasso Prediction with sklearn Quiz
The line should be:
```
regression.predict([[2,4]])
```

### Lesson 12.19 Lasso Coefficients
To obtain the coefficients:
```
regression.coef_
```

### Lesson 12.23 Overfitting a Decision Tree 1
You would expect that the accuracy on a test set for an overfit decision tree would be low.

### Lesson 12.24 Overfitting a Decision Tree 2
Conversely, it would have a high accuracy for the training set.

### Lesson 12.25 Number of Features and Overfitting
There are 150 training points.

### Lesson 12.26 Accuracy of Your Overfit Decision Tree
The accuracy of the decision tree is 0.947667804323.

### Lesson 12.27 Identify the Most Powerful Features
The importance of the most important feature is 0.764705882353. The number of the feature is 33614. It is the only feature that has an importance greater than 0.2.

### Lesson 12.28 Use TfIdf to Get the Most Important Word
The most important word is "sshacklensf".

### Lesson 12.29 Remove, Repeat
The next most important word is "cgermannsf".

### Lesson 12.30 Checking Important Features Again
After removing "cgermannsf" the next most important word is "houectect". It is unclear whether this is a signature.

### Lesson 12.31 Accuracy of the Overfit Tree
With the two signature words now removed, the accuracy of the decision tree is 0.816837315131.
